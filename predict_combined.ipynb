{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import customized modules\n",
    "from combined_models import lstm_deepcon\n",
    "from data_combined import Psicov150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amino acid indices\n",
    "aa2ix = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9,\n",
    "         'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
    "\n",
    "\n",
    "def aanum(ch):\n",
    "    if ch in aa2ix:\n",
    "        return aa2ix[ch]\n",
    "    else:\n",
    "        return 20\n",
    "\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    idxs = [aanum(w) for w in sequence]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, test_loader, pred_folder):\n",
    "    model.eval()\n",
    "    target_count = 0\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        for data in test_loader:\n",
    "            target_name = data['target'][0]\n",
    "            sequence = data['sequence'][0]\n",
    "            encoded_seq = encode_sequence(sequence).to(device)\n",
    "            \n",
    "            print('Predict {}/{} - {}'.format(target_count + 1, \n",
    "                                              len(test_loader.dataset), \n",
    "                                              target_name))\n",
    "            cov = data['cov']\n",
    "            cov = cov[0].to(device)\n",
    "\n",
    "            pred = model(cov, encoded_seq)\n",
    "            pred = pred[0]\n",
    "            # print('pred \\n', pred)\n",
    "            p = pred[0].cpu().numpy()\n",
    "            #print(p.shape)\n",
    "            seq_len = p.shape[1]\n",
    "\n",
    "            # write prediction to file\n",
    "            rr = open(os.path.join(pred_folder, target_name + '.rr'), 'w')\n",
    "            rr.write(sequence + \"\\n\")\n",
    "            \n",
    "            for i in range(0, seq_len):\n",
    "                for j in range(i, seq_len):\n",
    "                    if abs(i - j) < 5:\n",
    "                        continue\n",
    "                    rr.write(\"%i %i 0 8 %.5f\\n\" %(i+1, j+1, p[i][j]))\n",
    "            rr.close()\n",
    "\n",
    "            target_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test targets = 150\n"
     ]
    }
   ],
   "source": [
    "# load test target list\n",
    "seq_file = 'data/DeepCov/test/psicov150/id_seq.txt'\n",
    "test_target_file = 'data/DeepCov/test/psicov150/target.lst.sorted'\n",
    "test_target_list = []\n",
    "\n",
    "# set folder for storing prediction files\n",
    "pred_folder = 'data/DeepCov/test/psicov150/rr_combined/'\n",
    "\n",
    "with open(test_target_file) as target_file:\n",
    "    for line in target_file:\n",
    "        target = line.rstrip()\n",
    "        test_target_list.append(target)   \n",
    "\n",
    "print('Total test targets = {}'.format(len(test_target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_dataset = Psicov150('data/DeepCov/test/psicov150/', test_target_list, seq_file)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "# init model\n",
    "model_name = 'LSTM_DeepCon'\n",
    "\n",
    "if model_name == 'LSTM_DeepCon':\n",
    "    model = lstm_deepcon()\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model sucessfully loaded.\n",
      "Predict 1/150 - 1a3aA\n",
      "Predict 2/150 - 1a6mA\n",
      "Predict 3/150 - 1a70A\n",
      "Predict 4/150 - 1aapA\n",
      "Predict 5/150 - 1abaA\n",
      "Predict 6/150 - 1ag6A\n",
      "Predict 7/150 - 1aoeA\n",
      "Predict 8/150 - 1atlA\n",
      "Predict 9/150 - 1atzA\n",
      "Predict 10/150 - 1avsA\n",
      "Predict 11/150 - 1bdoA\n",
      "Predict 12/150 - 1bebA\n",
      "Predict 13/150 - 1behA\n",
      "Predict 14/150 - 1bkrA\n",
      "Predict 15/150 - 1brfA\n",
      "Predict 16/150 - 1bsgA\n",
      "Predict 17/150 - 1c44A\n",
      "Predict 18/150 - 1c52A\n",
      "Predict 19/150 - 1c9oA\n",
      "Predict 20/150 - 1cc8A\n",
      "Predict 21/150 - 1chdA\n",
      "Predict 22/150 - 1cjwA\n",
      "Predict 23/150 - 1ckeA\n",
      "Predict 24/150 - 1ctfA\n",
      "Predict 25/150 - 1cxyA\n",
      "Predict 26/150 - 1cznA\n",
      "Predict 27/150 - 1d0qA\n",
      "Predict 28/150 - 1d1qA\n",
      "Predict 29/150 - 1d4oA\n",
      "Predict 30/150 - 1dbxA\n",
      "Predict 31/150 - 1dixA\n",
      "Predict 32/150 - 1dlwA\n",
      "Predict 33/150 - 1dmgA\n",
      "Predict 34/150 - 1dqgA\n",
      "Predict 35/150 - 1dsxA\n",
      "Predict 36/150 - 1eazA\n",
      "Predict 37/150 - 1ej0A\n",
      "Predict 38/150 - 1ej8A\n",
      "Predict 39/150 - 1ek0A\n",
      "Predict 40/150 - 1f6bA\n",
      "Predict 41/150 - 1fcyA\n",
      "Predict 42/150 - 1fk5A\n",
      "Predict 43/150 - 1fl0A\n",
      "Predict 44/150 - 1fnaA\n",
      "Predict 45/150 - 1fqtA\n",
      "Predict 46/150 - 1fvgA\n",
      "Predict 47/150 - 1fvkA\n",
      "Predict 48/150 - 1fx2A\n",
      "Predict 49/150 - 1g2rA\n",
      "Predict 50/150 - 1g9oA\n",
      "Predict 51/150 - 1gbsA\n",
      "Predict 52/150 - 1gmiA\n",
      "Predict 53/150 - 1gmxA\n",
      "Predict 54/150 - 1guuA\n",
      "Predict 55/150 - 1gz2A\n",
      "Predict 56/150 - 1gzcA\n",
      "Predict 57/150 - 1h0pA\n",
      "Predict 58/150 - 1h2eA\n",
      "Predict 59/150 - 1h4xA\n",
      "Predict 60/150 - 1h98A\n",
      "Predict 61/150 - 1hdoA\n",
      "Predict 62/150 - 1hfcA\n",
      "Predict 63/150 - 1hh8A\n",
      "Predict 64/150 - 1htwA\n",
      "Predict 65/150 - 1hxnA\n",
      "Predict 66/150 - 1i1jA\n",
      "Predict 67/150 - 1i1nA\n",
      "Predict 68/150 - 1i4jA\n",
      "Predict 69/150 - 1i58A\n",
      "Predict 70/150 - 1i5gA\n",
      "Predict 71/150 - 1i71A\n",
      "Predict 72/150 - 1ihzA\n",
      "Predict 73/150 - 1iibA\n",
      "Predict 74/150 - 1im5A\n",
      "Predict 75/150 - 1iwdA\n",
      "Predict 76/150 - 1j3aA\n",
      "Predict 77/150 - 1jbeA\n",
      "Predict 78/150 - 1jbkA\n",
      "Predict 79/150 - 1jfuA\n",
      "Predict 80/150 - 1jfxA\n",
      "Predict 81/150 - 1jkxA\n",
      "Predict 82/150 - 1jl1A\n",
      "Predict 83/150 - 1jo0A\n",
      "Predict 84/150 - 1jo8A\n",
      "Predict 85/150 - 1josA\n",
      "Predict 86/150 - 1jvwA\n",
      "Predict 87/150 - 1jwqA\n",
      "Predict 88/150 - 1jyhA\n",
      "Predict 89/150 - 1k6kA\n",
      "Predict 90/150 - 1k7cA\n",
      "Predict 91/150 - 1k7jA\n",
      "Predict 92/150 - 1kidA\n",
      "Predict 93/150 - 1kq6A\n",
      "Predict 94/150 - 1kqrA\n",
      "Predict 95/150 - 1ktgA\n",
      "Predict 96/150 - 1ku3A\n",
      "Predict 97/150 - 1kw4A\n",
      "Predict 98/150 - 1lm4A\n",
      "Predict 99/150 - 1lo7A\n",
      "Predict 100/150 - 1lpyA\n",
      "Predict 101/150 - 1m4jA\n",
      "Predict 102/150 - 1m8aA\n",
      "Predict 103/150 - 1mk0A\n",
      "Predict 104/150 - 1mugA\n",
      "Predict 105/150 - 1nb9A\n",
      "Predict 106/150 - 1ne2A\n",
      "Predict 107/150 - 1npsA\n",
      "Predict 108/150 - 1nrvA\n",
      "Predict 109/150 - 1ny1A\n",
      "Predict 110/150 - 1o1zA\n",
      "Predict 111/150 - 1p90A\n",
      "Predict 112/150 - 1pchA\n",
      "Predict 113/150 - 1pkoA\n",
      "Predict 114/150 - 1qf9A\n",
      "Predict 115/150 - 1qjpA\n",
      "Predict 116/150 - 1ql0A\n",
      "Predict 117/150 - 1r26A\n",
      "Predict 118/150 - 1roaA\n",
      "Predict 119/150 - 1rw1A\n",
      "Predict 120/150 - 1rw7A\n",
      "Predict 121/150 - 1rybA\n",
      "Predict 122/150 - 1smxA\n",
      "Predict 123/150 - 1svyA\n",
      "Predict 124/150 - 1t8kA\n",
      "Predict 125/150 - 1tifA\n",
      "Predict 126/150 - 1tqgA\n",
      "Predict 127/150 - 1tqhA\n",
      "Predict 128/150 - 1tzvA\n",
      "Predict 129/150 - 1vfyA\n",
      "Predict 130/150 - 1vhuA\n",
      "Predict 131/150 - 1vjkA\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (87) must match the size of tensor b (88) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-89734143fedc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-13eec83ae40c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, device, test_loader, pred_folder)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# print('pred \\n', pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experiments/2019/bioinf/folding/DEEPCON/combined_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cov, aa_ids)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# alternatively, we can output the two separately then compute mean of the two BCE loss functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# do try and compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnn_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (87) must match the size of tensor b (88) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # load checkpoint\n",
    "    checkpoint = torch.load(model_name+'_checkpoint.pth.tar', map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print('Pretrained model sucessfully loaded.')\n",
    "except:\n",
    "    print('Model loading failed. Stop prediction.')\n",
    "    exit()\n",
    "else:\n",
    "    model.to(device)\n",
    "    predict(model, device, test_loader, pred_folder)\n",
    "    print('Prediction done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
